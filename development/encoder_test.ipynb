{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "ROOT DIR:  /media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/train\n",
      "Number of features found:  22551  in  ['/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/train/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915243047392.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/train/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915243547836.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/train/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915244048280.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/train/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915244548143.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/train/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915245048008.pt']\n",
      "Threshold is  None\n",
      "22551 22551\n",
      "ROOT DIR:  /media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/val\n",
      "Number of features found:  4786  in  ['/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/val/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915677048443.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/val/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915677548854.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/val/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915678048739.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/val/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915678548645.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/val/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915679048498.pt']\n",
      "Threshold is  None\n",
      "4786 4786\n",
      "ROOT DIR:  /media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/test\n",
      "Number of features found:  4797  in  ['/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/test/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915719047399.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/test/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915719547865.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/test/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915720047703.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/test/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915720547578.pt', '/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/test/features/n008-2018-05-21-11-06-59-0400__LIDAR_TOP__1526915720947363.pt']\n",
      "Threshold is  None\n",
      "4797 4797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409ed136303743c9b534f39711227243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/705 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Accumulate the training loss\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Calculate average loss over the training data\u001b[39;00m\n\u001b[1;32m    108\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets.activation_dataset import ActivationDataset\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm  # For progress bar\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16,apply=True):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.apply = apply\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x) if self.apply else y.expand_as(x)\n",
    "\n",
    "\n",
    "\n",
    "class AutoencoderWithSE(nn.Module):\n",
    "    def __init__(self, in_channels, latent_channels, reduction=16):\n",
    "        super(AutoencoderWithSE, self).__init__()\n",
    "        self.se_block = SEBlock(in_channels, reduction)\n",
    "        self.encoder = nn.Conv2d(in_channels, latent_channels, kernel_size=1)\n",
    "        self.decoder = nn.Conv2d(latent_channels, in_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply Squeeze-and-Excite block before encoding\n",
    "        x = self.se_block(x)\n",
    "        # Encoding with 1x1 convolution\n",
    "        encoded = self.encoder(x)\n",
    "        # Decoding with 1x1 convolution\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming input is a batch of images with 3 channels (e.g., RGB)\n",
    "    act= {\n",
    "    'config': {\n",
    "      'root_dir': \"/media/wmg-5gcat/Co-op Autonomy 2/Hakan/custom_dataset/nus_centerpoint_activations_filtered_objects_lonly/\"  ,\n",
    "      'label_file': 'nus_centerpoint_labels_filtered_objects_lonly.csv',\n",
    "      'classes': ['No Error', 'Error'],\n",
    "      'label_field': 'is_missed',\n",
    "      'layer': [0,1,2],\n",
    "      'is_multi_feature': True,\n",
    "      'is_sparse': True,\n",
    "      'extension':'.pt',\n",
    "      'name': 'nuscenes'\n",
    "      }\n",
    "      }\n",
    "    act_train = deepcopy(act)\n",
    "    act_train['config']['root_dir'] = os.path.join(act['config']['root_dir'], 'train')\n",
    "    act_train_dataset = ActivationDataset(act_train['config'])\n",
    "    act_val = deepcopy(act)\n",
    "    act_val['config']['root_dir'] = os.path.join(act['config']['root_dir'], 'val')\n",
    "    act_val_dataset = ActivationDataset(act_val['config'])\n",
    "    act_test = deepcopy(act)\n",
    "    act_test['config']['root_dir'] = os.path.join(act['config']['root_dir'], 'test')\n",
    "    act_test_dataset = ActivationDataset(act_test['config'])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(act_train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(act_val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(act_test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Define the autoencoder with Squeeze-and-Excite\n",
    "    model = AutoencoderWithSE(in_channels=256, latent_channels=1)  # Compressing to 16 channels\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 20  # Number of epochs\n",
    "    model.cuda()  # Move model to GPU if available\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # Training phase\n",
    "        for data,_,_ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs = data[0] # Move data to GPU if available\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            _, outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = mse_loss(outputs, inputs)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate the training loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate average loss over the training data\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data,_,_ in val_loader:\n",
    "                print(len(data))\n",
    "                inputs = data[0]  # Move data to GPU if available\n",
    "                \n",
    "                # Forward pass\n",
    "                _, outputs = model(inputs)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = mse_loss(outputs, inputs)\n",
    "                \n",
    "                # Accumulate the validation loss\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Calculate average loss over the validation data\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # After training, evaluate on the test set if needed\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data,_,_ in test_loader:\n",
    "            inputs = data[0] # Move data to GPU if available\n",
    "            \n",
    "            # Forward pass\n",
    "            _, outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = mse_loss(outputs, inputs)\n",
    "            \n",
    "            # Accumulate the test loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Calculate average loss over the test data\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "        # Forward pass\n",
    "\n",
    "        # encoded, decoded = model(tens[0].unsqueeze(0).cpu())\n",
    "        \n",
    "        # print(\"Encoded shape:\", encoded.shape)\n",
    "        # print(\"Decoded shape:\", decoded.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
