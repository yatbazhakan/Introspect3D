{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchvision.models.mobilenetv3 import mobilenet_v3_large,MobileNet_V3_Large_Weights\n",
    "from torchvision.models.shufflenetv2 import shufflenet_v2_x1_0,ShuffleNet_V2_X1_0_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16,apply=True):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.apply = apply\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)*x if self.apply else self.sigmoid(out) \n",
    "    \n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16,apply=True):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.apply = apply\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x) if self.apply else y.expand_as(x)\n",
    "\n",
    "class SuperImageStich(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperImageStich, self).__init__()\n",
    "        #This is specific to 256 channel 90x90 samples \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, c, h, w = x.size()\n",
    "        \n",
    "        final_tensor = torch.zeros((batch, 1, 16*90, 16*90))\n",
    "        for b in range(batch):\n",
    "            for i in range(16):\n",
    "                for j in range(16):\n",
    "                    start_row = i * 90\n",
    "                    start_col = j * 90\n",
    "                    img = x[b, i * 16 + j]\n",
    "                    final_tensor[b, 0, start_row:start_row + 90, start_col:start_col + 90] = img\n",
    "\n",
    "        return  final_tensor\n",
    "    \n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        # Load the pre-trained ResNet-18 model\n",
    "        if pretrained:\n",
    "            self.resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        else:\n",
    "            self.resnet = models.resnet18(weights=None)        \n",
    "        # Modify the first convolutional layer to accept 256 input channels\n",
    "        original_conv1 = self.resnet.conv1\n",
    "        self.resnet.conv1 = nn.Conv2d(256, original_conv1.out_channels, \n",
    "                                      kernel_size=original_conv1.kernel_size, \n",
    "                                      stride=original_conv1.stride, \n",
    "                                      padding=original_conv1.padding, \n",
    "                                      bias=original_conv1.bias)\n",
    "        \n",
    "        if pretrained:\n",
    "            # Copy weights from the first layer of the pre-trained model\n",
    "            with torch.no_grad():\n",
    "                # Initialize the weights for the new conv1 layer\n",
    "                self.resnet.conv1.weight[:, :3, :, :] = original_conv1.weight\n",
    "                # Average the pre-trained weights and copy them to the remaining channels\n",
    "                if original_conv1.weight.size(1) < 256:\n",
    "                    for i in range(3, 256):\n",
    "                        self.resnet.conv1.weight[:, i, :, :] = torch.mean(original_conv1.weight, dim=1)\n",
    "        \n",
    "        # The rest of the layers will remain the same as the pre-trained ResNet-18 model\n",
    "        self.resnet.fc = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "class CustomMobileNetV3(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(CustomMobileNetV3, self).__init__()\n",
    "        # Load the pre-trained MobileNetV3 model\n",
    "        if pretrained:\n",
    "            self.mobilenet = models.mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n",
    "        else:\n",
    "            self.mobilenet = models.mobilenet_v3_large(weights=None)\n",
    "        \n",
    "        # Modify the first convolutional layer to accept 256 input channels\n",
    "        original_conv1 = self.mobilenet.features[0][0]\n",
    "        self.mobilenet.features[0][0] = nn.Conv2d(256, original_conv1.out_channels, \n",
    "                                                  kernel_size=original_conv1.kernel_size, \n",
    "                                                  stride=original_conv1.stride, \n",
    "                                                  padding=original_conv1.padding, \n",
    "                                                  bias=original_conv1.bias)\n",
    "        \n",
    "        if pretrained:\n",
    "            # Copy weights from the first layer of the pre-trained model\n",
    "            with torch.no_grad():\n",
    "                # Initialize the weights for the new conv1 layer\n",
    "                self.mobilenet.features[0][0].weight[:, :3, :, :] = original_conv1.weight\n",
    "                # Average the pre-trained weights and copy them to the remaining channels\n",
    "                if original_conv1.weight.size(1) < 256:\n",
    "                    for i in range(3, 256):\n",
    "                        self.mobilenet.features[0][0].weight[:, i, :, :] = torch.mean(original_conv1.weight, dim=1)\n",
    "        \n",
    "        # The classifier remains the same\n",
    "        self.mobilenet.classifier[3] = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "\n",
    "class CustomShuffleNetV2(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(CustomShuffleNetV2, self).__init__()\n",
    "        # Load the pre-trained ShuffleNetV2 model\n",
    "        if pretrained:\n",
    "            self.shufflenet = models.shufflenet_v2_x1_0(weights=ShuffleNet_V2_X1_0_Weights.DEFAULT)\n",
    "        else:\n",
    "            self.shufflenet = models.shufflenet_v2_x1_0(weights=None)\n",
    "        \n",
    "        # Modify the first convolutional layer to accept 256 input channels\n",
    "        original_conv1 = self.shufflenet.conv1[0]\n",
    "        self.shufflenet.conv1[0] = nn.Conv2d(256, original_conv1.out_channels, \n",
    "                                             kernel_size=original_conv1.kernel_size, \n",
    "                                             stride=original_conv1.stride, \n",
    "                                             padding=original_conv1.padding, \n",
    "                                             bias=original_conv1.bias)\n",
    "        \n",
    "        if pretrained:\n",
    "            # Copy weights from the first layer of the pre-trained model\n",
    "            with torch.no_grad():\n",
    "                # Initialize the weights for the new conv1 layer\n",
    "                self.shufflenet.conv1[0].weight[:, :3, :, :] = original_conv1.weight\n",
    "                # Average the pre-trained weights and copy them to the remaining channels\n",
    "                if original_conv1.weight.size(1) < 256:\n",
    "                    for i in range(3, 256):\n",
    "                        self.shufflenet.conv1[0].weight[:, i, :, :] = torch.mean(original_conv1.weight, dim=1)\n",
    "        \n",
    "        # The classifier remains the same\n",
    "        self.shufflenet.fc = Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.shufflenet(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 256, 90, 90])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(14, 256, 90, 90)\n",
    "model = ChannelAttention(256)\n",
    "print(model(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 90, 90])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(2, 256, 90, 90)\n",
    "model = SEBlock(256)\n",
    "print(model(test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 1440, 1440])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(4, 256, 90, 90)\n",
    "model = SuperImageStich()\n",
    "output = model(test)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(4, 256, 90, 90)\n",
    "model = CustomResNet18()\n",
    "output = model(test)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /home/yatbaz_h@WMGDS.WMG.WARWICK.AC.UK/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 78.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1280])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(4, 256, 90, 90)\n",
    "model = CustomMobileNetV3()\n",
    "output = model(test)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /home/yatbaz_h@WMGDS.WMG.WARWICK.AC.UK/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n",
      "100%|██████████| 8.79M/8.79M [00:00<00:00, 13.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024])\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(4, 256, 90, 90)\n",
    "model = CustomShuffleNetV2()\n",
    "output = model(test)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import N"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
