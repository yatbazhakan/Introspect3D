{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c open3d-admin open3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# pth = \"/mnt/ssd2/custom_dataset/nus_centerpoint_activations_filtered/nus_centerpoint_labels_filtered.csv\"\n",
    "pth = \"/mnt/ssd2/custom_dataset/kitti_pointpillars_activations_filtered/kitti_point_pillars_labels_filtered.csv\"\n",
    "\n",
    "df = pd.read_csv(pth)\n",
    "df['severity'] = df['missed_objects']/df['total_objects']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['severity'] !=0]['severity'].hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "fpth = \"/mnt/ssd2/custom_dataset/kitti_pointpillars_activations_filtered/features/\"\n",
    "paths = glob(fpth + \"*.npy\")\n",
    "arr = np.load(paths[0])\n",
    "ratios = []\n",
    "# #histogram of non zero values\n",
    "# for path in paths:\n",
    "#     arr = np.load(path)\n",
    "#     ratios.append(np.count_nonzero(arr)/arr.flatten().shape[0])\n",
    "# print(np.mean(ratios))\n",
    "# plt.hist(test[test!=0], bins=25)\n",
    "# #Count of non zero values\n",
    "# print(np.count_nonzero(test))\n",
    "# print(test.flatten().shape[0])\n",
    "# #ratio of non zero values\n",
    "# print(np.count_nonzero(test)/test.flatten().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/ssd2/Introspect3D/notebooks/development_plaground.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/ssd2/Introspect3D/notebooks/development_plaground.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m graphs \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/ssd2/Introspect3D/notebooks/development_plaground.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m paths:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/ssd2/Introspect3D/notebooks/development_plaground.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/ssd2/Introspect3D/notebooks/development_plaground.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     edge_index \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/ssd2/Introspect3D/notebooks/development_plaground.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     node_featuers \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/pointcept/lib/python3.8/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/anaconda3/envs/pointcept/lib/python3.8/site-packages/numpy/lib/format.py:801\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    800\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    802\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    803\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    804\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from datetime import datetime\n",
    "graphs = []\n",
    "for path in paths:\n",
    "    arr = np.load(path)\n",
    "    edge_index = []\n",
    "    node_featuers = []\n",
    "    c,h,w = arr.shape\n",
    "    # start= datetime.now()\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            for k in range(arr.shape[2]):\n",
    "                if arr[i,j,k] != 0:\n",
    "                    node_index_1d = c*h*i + c*j + k\n",
    "                    node_featuers.append([i,j,k,arr[i,j,k]])\n",
    "                    if i != arr.shape[0]-1 and arr[i+1,j,k] != 0:\n",
    "                        neighbour_node_index_1d = c*h*(i+1) + c*j + k\n",
    "                        edge_index.append([node_index_1d, neighbour_node_index_1d+1])\n",
    "                    if j != arr.shape[1]-1 and arr[i,j+1,k] != 0:\n",
    "                        neighbour_node_index_1d = c*h*i + c*(j+1) + k\n",
    "                        #find node count using dimensions and i,j,k\n",
    "                        edge_index.append([node_index_1d, neighbour_node_index_1d])\n",
    "                    if k != arr.shape[2]-1 and arr[i,j,k+1] != 0:\n",
    "                        neighbour_node_index_1d = c*h*i + c*j + (k+1)\n",
    "                        edge_index.append([node_index_1d, neighbour_node_index_1d])\n",
    "    graphs.append(Data(x = torch.tensor(node_featuers), edge_index = torch.tensor(edge_index).t().contiguous()))\n",
    "# end = datetime.now()\n",
    "print(len(graphs))\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.708379\n"
     ]
    }
   ],
   "source": [
    "edge_index = []\n",
    "node_featuers = []\n",
    "start2 = datetime.now()\n",
    "for i in range(arr.shape[0]):\n",
    "    for j in range(arr.shape[1]):\n",
    "        for k in range(arr.shape[2]):\n",
    "            if arr[i,j,k] != 0:\n",
    "                node_index_1d = c*h*i + c*j + k\n",
    "                node_featuers.append([i,j,k,arr[i,j,k]])\n",
    "                if i != arr.shape[0]-1 and arr[i+1,j,k] != 0:\n",
    "                    neighbour_node_index_1d = c*h*(i+1) + c*j + k\n",
    "                    edge_index.append([node_index_1d, neighbour_node_index_1d+1])\n",
    "                if j != arr.shape[1]-1 and arr[i,j+1,k] != 0:\n",
    "                    neighbour_node_index_1d = c*h*i + c*(j+1) + k\n",
    "                    #find node count using dimensions and i,j,k\n",
    "                    edge_index.append([node_index_1d, neighbour_node_index_1d])\n",
    "                if k != arr.shape[2]-1 and arr[i,j,k+1] != 0:\n",
    "                    neighbour_node_index_1d = c*h*i + c*j + (k+1)\n",
    "                    edge_index.append([node_index_1d, neighbour_node_index_1d])\n",
    "end2 = datetime.now()\n",
    "print(end2-start2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.245483\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def index_to_1d(index, c, h):\n",
    "    return c_h_product * index[0] + c * index[1] + index[2]\n",
    "# Assuming 'arr' is a numpy 3D array and 'c' and 'h' are constants defined elsewhere.\n",
    "start = datetime.now()\n",
    "non_zero_indices = np.argwhere(arr != 0)\n",
    "node_features2 = [[i, j, k, arr[i, j, k]] for i, j, k in non_zero_indices]\n",
    "\n",
    "c_h_product = c * h\n",
    "node_index_1d_array = c_h_product * non_zero_indices[:, 0] + c * non_zero_indices[:, 1] + non_zero_indices[:, 2]\n",
    "\n",
    "edge_index2 = []\n",
    "\n",
    "# For i connections\n",
    "valid_i_indices = non_zero_indices[non_zero_indices[:, 0] < arr.shape[0] - 1]\n",
    "for index in valid_i_indices:\n",
    "    if arr[index[0] + 1, index[1], index[2]] != 0:\n",
    "        node_index_1d = index_to_1d(index, c, h)\n",
    "        neighbour_node_index_1d = index_to_1d(index + [1, 0, 0], c, h)\n",
    "        edge_index2.append([node_index_1d, neighbour_node_index_1d])\n",
    "\n",
    "# For j connections\n",
    "valid_j_indices = non_zero_indices[non_zero_indices[:, 1] < arr.shape[1] - 1]\n",
    "for index in valid_j_indices:\n",
    "    if arr[index[0], index[1] + 1, index[2]] != 0:\n",
    "        node_index_1d = index_to_1d(index, c, h)\n",
    "        neighbour_node_index_1d = index_to_1d(index + [0, 1, 0], c, h)\n",
    "        edge_index2.append([node_index_1d, neighbour_node_index_1d])\n",
    "\n",
    "# For k connections\n",
    "valid_k_indices = non_zero_indices[non_zero_indices[:, 2] < arr.shape[2] - 1]\n",
    "for index in valid_k_indices:\n",
    "    if arr[index[0], index[1], index[2] + 1] != 0:\n",
    "        node_index_1d = index_to_1d(index, c, h)\n",
    "        neighbour_node_index_1d = index_to_1d(index + [0, 0, 1], c, h)\n",
    "        edge_index2.append([node_index_1d, neighbour_node_index_1d])\n",
    "end = datetime.now()\n",
    "print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.747840\n"
     ]
    }
   ],
   "source": [
    "def index_to_1d(index, c, h):\n",
    "    return (index[0] * h + index[1]) * c + index[2]\n",
    "# Find the indices of non-zero elements.\n",
    "start3 = datetime.now()\n",
    "non_zero_indices = np.transpose(np.nonzero(arr))\n",
    "\n",
    "# Compute the linear index for non-zero elements.\n",
    "linear_indices = c_h_product * non_zero_indices[:, 0] + c * non_zero_indices[:, 1] + non_zero_indices[:, 2]\n",
    "\n",
    "# Pad the array with zeros on all sides to avoid boundary checks.\n",
    "padded_arr = np.pad(arr, ((1, 1), (1, 1), (1, 1)), mode='constant')\n",
    "\n",
    "# Shift the padded array and compare to find connections.\n",
    "# Shift in the 'i' direction.\n",
    "shift_i = padded_arr[2:, 1:-1, 1:-1] != 0\n",
    "# Shift in the 'j' direction.\n",
    "shift_j = padded_arr[1:-1, 2:, 1:-1] != 0\n",
    "# Shift in the 'k' direction.\n",
    "shift_k = padded_arr[1:-1, 1:-1, 2:] != 0\n",
    "\n",
    "# Find the edges using the shifts and the mask for non-zero connections.\n",
    "edges_i = np.argwhere(shift_i & (arr != 0))\n",
    "edges_j = np.argwhere(shift_j & (arr != 0))\n",
    "edges_k = np.argwhere(shift_k & (arr != 0))\n",
    "\n",
    "# Compute edge connections using list comprehensions.\n",
    "edge_index3 = [[index_to_1d(idx, c, h), index_to_1d(idx + [1, 0, 0], c, h)] for idx in edges_i] + \\\n",
    "             [[index_to_1d(idx, c, h), index_to_1d(idx + [0, 1, 0], c, h)] for idx in edges_j] + \\\n",
    "             [[index_to_1d(idx, c, h), index_to_1d(idx + [0, 0, 1], c, h)] for idx in edges_k]\n",
    "\n",
    "# Flatten the list of edges and remove duplicates if necessary.\n",
    "edge_index3 = np.unique(edge_index3, axis=0)\n",
    "\n",
    "# Prepare the node features as a list of lists.\n",
    "node_features3 = [[*idx, arr[tuple(idx)]] for idx in non_zero_indices]\n",
    "end3 = datetime.now()\n",
    "print(end3-start3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 0, 0.73311347]\n",
      "[2, 0, 0, 0.73311347]\n",
      "[2, 0, 0, 0.73311347]\n",
      "140715 140715 140715\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "print(node_featuers[ix])\n",
    "print(node_features2[ix])\n",
    "print(node_features3[ix])\n",
    "basic = edge_index[ix]\n",
    "print(len(edge_index), len(edge_index2), len(edge_index3))\n",
    "# print(edge_index[ix])\n",
    "# print(edge_index2[ix])\n",
    "# print(edge_index3[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 1, 0.7341482]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of ratios\n",
    "plt.hist(ratios, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "# import open3d as o3d\n",
    "# print(\"Open3D Version: \" + o3d.__version__)\n",
    "# o3d.visualization.webrtc_server.enable_webrtc()\n",
    "kitti_velodyne_path= r\"D:\\introspectionBase\\datasets\\Kitti\\raw\\training\\velodyne\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        print(avg_out.shape)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        print(max_out.shape)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))\n",
    "        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None,apply=True):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels if inter_channels is not None else in_channels\n",
    "        self.apply = apply\n",
    "\n",
    "        self.g = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.theta = nn.Conv2d(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.phi = nn.Conv2d(in_channels=self.inter_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.W = nn.Conv2d(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0)\n",
    "        nn.init.constant_(self.W.weight, 0)\n",
    "        nn.init.constant_(self.W.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "        theta_x = theta_x.permute(0, 2, 1)\n",
    "        phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "\n",
    "        f = torch.matmul(theta_x, phi_x)\n",
    "        f_div_C = F.softmax(f, dim=-1)\n",
    "\n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        W_y = self.W(y)\n",
    "        z = W_y + x\n",
    "\n",
    "        return z if self.apply else W_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = torch.ones(1, 256, 1, 1)\n",
    "\n",
    "# Input feature map of shape [1, 256, 62, 54]\n",
    "x = torch.ones(1, 256, 62, 54)\n",
    "\n",
    "# This operation is valid due to broadcasting\n",
    "result = NonLocalBlock(256)(x)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "t = models.resnet18()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix_from_corners(corners):\n",
    "    \"\"\"\n",
    "    Get the rotation matrix from 8 corners of a 3D bounding box.\n",
    "    \n",
    "    Parameters:\n",
    "        corners (numpy.ndarray): 3x8 array containing the coordinates of the 8 corners.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assume the corners are ordered such that:\n",
    "    # - corners[:, 0] and corners[:, 1] are opposite corners on the \"bottom\" face of the box\n",
    "    # - corners[:, 0] and corners[:, 4] are opposite corners on the \"front\" face of the box\n",
    "    # - corners[:, 0] and corners[:, 3] are opposite corners on the \"left\" face of the box\n",
    "    \n",
    "    # Compute the vectors representing the edges\n",
    "    edge1 = corners[:, 1] - corners[:, 0]  # Vector from corner 0 to corner 1\n",
    "    edge2 = corners[:, 4] - corners[:, 0]  # Vector from corner 0 to corner 4\n",
    "    edge3 = corners[:, 3] - corners[:, 0]  # Vector from corner 0 to corner 3\n",
    "    \n",
    "    # Normalize the vectors\n",
    "    edge1 /= np.linalg.norm(edge1)\n",
    "    edge2 /= np.linalg.norm(edge2)\n",
    "    edge3 /= np.linalg.norm(edge3)\n",
    "    \n",
    "    # Construct the rotation matrix\n",
    "    R = np.column_stack((edge1, edge2, edge3))\n",
    "    \n",
    "    return R\n",
    "def is_inside_ellipse(x, y, a, b):\n",
    "    return (x**2 / a**2) + (y**2 / b**2) <= 1\n",
    "def is_outside_ellipse(x, y, a, b):\n",
    "    return (x**2 / a**2) + (y**2 / b**2) > 1\n",
    "def set_custom_view(vis):\n",
    "    ctr = vis.get_view_control()\n",
    "    \n",
    "    # Create an extrinsic matrix for camera placement\n",
    "    extrinsic = np.eye(4)\n",
    "    extrinsic[0:3, 3] = [-10, 0, 0]  # Set camera position (x, y, z)\n",
    "    \n",
    "    # Create a rotation matrix for 30-degree downward view\n",
    "    rotation = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, np.cos(np.radians(-160)), -np.sin(np.radians(-160))],\n",
    "        [0, np.sin(np.radians(-160)), np.cos(np.radians(-160))]\n",
    "    ])\n",
    "    \n",
    "    # Apply rotation to the extrinsic matrix\n",
    "    extrinsic[0:3, 0:3] = rotation\n",
    "    \n",
    "    # Set the extrinsic matrix to the camera parameters\n",
    "    cam_params = ctr.convert_to_pinhole_camera_parameters()\n",
    "    cam_params.extrinsic = extrinsic\n",
    "    ctr.convert_from_pinhole_camera_parameters(cam_params)\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0.5, 0.5, 0.5])\n",
    "\n",
    "def load_velodyne_points(filename):\n",
    "    points = np.fromfile(filename, dtype=np.float32).reshape(-1, 4)\n",
    "    return points\n",
    "def read_calib_file(calib_file):\n",
    "    with open(calib_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        calibration = {}\n",
    "\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            try:\n",
    "                key, value = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            calibration[key] = np.array([float(x) for x in value.strip().split()])\n",
    "        return calibration\n",
    "def compute_colors_from_distance(points,max_distance):\n",
    "    #If no disatance given return all black\n",
    "    if max_distance==None:\n",
    "        return np.zeros((points.shape[0],3))\n",
    "    distances = np.linalg.norm(points[:, :3], axis=1)\n",
    "    normalized_distances = distances / max_distance\n",
    "    return plt.cm.jet(normalized_distances)[:,:3]\n",
    "def create_point_cloud(points,distance=None):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points[:, :3])\n",
    "    colors = compute_colors_from_distance(points,distance)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return pcd\n",
    "def plot_bounding_box_from_corners(corners,offset =0, calib=None, color=[0, 1, 0]):\n",
    "    # Define the lines connecting the corners based on their indices\n",
    "\n",
    "    lines = [[0, 1], [1, 2], [2, 3], [3, 0],\n",
    "             [4, 5], [5, 6], [6, 7], [7, 4],\n",
    "             [0, 4], [1, 5], [2, 6], [3, 7]]\n",
    "\n",
    "    # Create a LineSet object\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = o3d.utility.Vector3dVector(corners)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector([color for i in range(len(lines))])\n",
    "\n",
    "    return line_set\n",
    "def filter_objects_outside_ellipse(objects, a, b,offset=5,axis=0):\n",
    "    \"\"\"\n",
    "    Filters ground truth objects to only include those outside a specified ellipse.\n",
    "\n",
    "    Parameters:\n",
    "        objects (list): The input objects, each as a dictionary.\n",
    "        a (float): Semi-major axis length of the ellipse.\n",
    "        b (float): Semi-minor axis length of the ellipse.\n",
    "\n",
    "    Returns:\n",
    "        list: The filtered objects.\n",
    "    \"\"\"\n",
    "    filtered_objects = []\n",
    "    \n",
    "    for obj in objects:\n",
    "        # print(obj)\n",
    "        if 'corners' not in obj.keys():\n",
    "            x, y = obj['x'], obj['y']\n",
    "            \n",
    "            # Generate corner points for the box\n",
    "            dx, dy = obj['dx'], obj['dy']\n",
    "\n",
    "        else:\n",
    "            x,y,_ = obj['real_center']\n",
    "        dx, dy = obj['dx'], obj['dy']\n",
    "    \n",
    "        # Check if any corner point is inside the ellipse\n",
    "        corners = np.array([\n",
    "                [x - dx/2, y - dy/2],\n",
    "                [x - dx/2, y + dy/2],\n",
    "                [x + dx/2, y - dy/2],\n",
    "                [x + dx/2, y + dy/2]\n",
    "            ])\n",
    "        adjusted_corners_x = corners[:, axis] + offset\n",
    "        inside_ellipse = is_inside_ellipse(adjusted_corners_x, corners[:, 1], a, b)\n",
    "        if np.any(inside_ellipse):\n",
    "            filtered_objects.append(obj)\n",
    "    # print(filtered_objects)\n",
    "    return filtered_objects\n",
    "\n",
    "def create_oriented_bounding_box_gt(box_params, color=(0, 1, 0),calib=None, offset=0,axis=0):\n",
    "    center = np.array([box_params['x'], box_params['y'], box_params['z']/2])\n",
    "    extent = np.array([box_params['dx'], box_params['dy'], box_params['dz']])\n",
    "    R = box_params['yaw']\n",
    "\n",
    "    # Tr_velo_to_cam = calib['Tr_velo_to_cam'].reshape(3, 4)\n",
    "    if(\"corners\" in box_params.keys()):\n",
    "    # # Convert center to homogeneous coordinates and transform to LiDAR coordinates\n",
    "    # point_homogeneous = np.hstack((center, np.ones(1)))\n",
    "    # center_tr = transform_camera_to_lidar(point_homogeneous, Tr_velo_to_cam)\n",
    "        center = box_params['real_center']\n",
    "        coners = box_params['corners']\n",
    "        # coners[:,2] /=2\n",
    "        coners[:,axis] += offset\n",
    "        return plot_bounding_box_from_corners(coners,offset=offset, calib=calib, color=color)\n",
    "        # R_empty = np.eye(3)\n",
    "        # obb = o3d.geometry.OrientedBoundingBox(center=real_center, R=R, extent=extent)\n",
    "        # cntr = o3d.geometry.OrientedBoundingBox(center=real_center, R=R, extent=[0.1,0.1,0.1])\n",
    "        # cntr.color = (1,1,1)\n",
    "        # obb.color = color\n",
    "        # return obb, cntr\n",
    "    # Rotate around the Y-axis for KITTI's rotation_y\n",
    "    # print(\"Plotting from center\")\n",
    "    # Create OrientedBoundingBox\n",
    "    obb = o3d.geometry.OrientedBoundingBox(center=center, R=R, extent=extent)\n",
    "    cntr = o3d.geometry.OrientedBoundingBox(center=center, R=R, extent=[0.1,0.1,0.1])\n",
    "    cntr.color = (1,1,1)\n",
    "    obb.color = color \n",
    "    \n",
    "    return obb\n",
    "def filter_points_inside_ellipse(points, a, b,offset=5):\n",
    "    x, y, z = points[:, 0]+offset, points[:, 1], points[:, 2]\n",
    "    inside = is_inside_ellipse(x, y, a, b)\n",
    "    return points[inside]\n",
    "def filter_points_outside_ellipse(points, a, b,offset=5):\n",
    "    x, y, z = points[:, 0]+offset, points[:, 1], points[:, 2]\n",
    "    outside = is_outside_ellipse(x, y, a, b)\n",
    "    return points[outside]\n",
    "def read_kitti_label_file(bin_file_path, filter_classes=['Car', 'Pedestrian', 'Cyclist']):\n",
    "    \"\"\"\n",
    "    Reads a KITTI label .txt file and returns a list of dictionaries containing\n",
    "    object type and bounding box parameters, filtered by specified classes.\n",
    "\n",
    "    Parameters:\n",
    "        txt_file_path (str): Path to the KITTI label .txt file.\n",
    "        filter_classes (List[str]): List of classes to include.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries containing 'type', 'x', 'y', 'z', 'dx', 'dy', 'dz', and 'yaw'.\n",
    "    \"\"\"\n",
    "    txt_file_path = bin_file_path.replace('.bin', '.txt').replace(\"velodyne\",\"label_2\")\n",
    "    calib_file_path = bin_file_path.replace('.bin', '.txt').replace(\"velodyne\",\"calib\")\n",
    "    calib = read_calib_file(calib_file_path)\n",
    "    objects = []\n",
    "    from math import cos,sin\n",
    "\n",
    "    with open(txt_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.strip().split(' ')\n",
    "            obj_type = tokens[0]\n",
    "            if obj_type not in filter_classes:\n",
    "                continue\n",
    "            # print(line)\n",
    "            dimensions_height, dimensions_width, dimensions_length = map(float, tokens[8:11])\n",
    "            location_x, location_y, location_z = map(float, tokens[11:14])\n",
    "            center_tr = np.array([location_x, location_y, location_z])\n",
    "            rotation_y = float(tokens[14])\n",
    "            l_div_2 = dimensions_length / 2\n",
    "            x_corners = [l_div_2, l_div_2, -l_div_2, -l_div_2, l_div_2, l_div_2, -l_div_2, -l_div_2]\n",
    "            w_div_2 = dimensions_width / 2\n",
    "            y_corners = [0, 0, 0, 0, -dimensions_height, -dimensions_height, -dimensions_height, -dimensions_height]\n",
    "            z_corners = [w_div_2, -w_div_2, -w_div_2, w_div_2, w_div_2, -w_div_2, -w_div_2, w_div_2]\n",
    "            corner_matrix = np.array([x_corners, y_corners, z_corners])\n",
    "            R = np.array([[cos(rotation_y),0,sin(rotation_y)],[0,1,0],[-sin(rotation_y),0,cos(rotation_y)]])\n",
    "            rotated_corners = np.matmul(R,corner_matrix)\n",
    "            translated_corners = rotated_corners + center_tr.reshape(3,1)\n",
    "            \n",
    "            Tr_velo_to_cam = calib_data['Tr_velo_to_cam'].reshape(3, 4)\n",
    "            Tr_velo_to_cam_extended = np.eye(4)  # Create a 4x4 identity matrix\n",
    "            Tr_velo_to_cam_extended[:3, :] = Tr_velo_to_cam  # Replace the top-left 3x4 block\n",
    "            \n",
    "            # rotation_component = np.eye(4)\n",
    "            # rotation_component[:3,:3] = Tr_velo_to_cam_extended[:3,:3]\n",
    "            \n",
    "            # translation_component = np.eye(4)\n",
    "            # translation_component[:3,3] = Tr_velo_to_cam_extended[:3,3]\n",
    "            \n",
    "            # inverse_rotation = np.linalg.inv(rotation_component)\n",
    "            # inverse_translation =  -translation_component\n",
    "            \n",
    "            # new_transform = np.eye(4)\n",
    "            # new_transform[:3,:3] = inverse_rotation[:3,:3]\n",
    "            # new_transform[:3,3] = inverse_translation[:3,3]\n",
    "\n",
    "            # print(new_transform.shape,translated_corners.shape)\n",
    "            T_inv = np.linalg.inv(Tr_velo_to_cam_extended)\n",
    "            Homogeneous_corners = np.ones((4,8))\n",
    "            Homogeneous_corners[:3,:] = translated_corners\n",
    "            translated_corners = np.matmul(T_inv,Homogeneous_corners)[:3,:]\n",
    "            real_center = np.mean(translated_corners,axis=1)\n",
    "            # print(translated_corners.shape)\n",
    "            # real_center = np.mean(translated_corners,axis=1)\n",
    "            # print(real_center)\n",
    "            objects.append({\n",
    "                'type': obj_type,\n",
    "                'x': real_center[0],\n",
    "                'y': real_center[1],\n",
    "                'z': real_center[2],\n",
    "                'dx': dimensions_length,\n",
    "                'dy': dimensions_height,\n",
    "                'dz': dimensions_width,\n",
    "                'yaw': o3d.geometry.get_rotation_matrix_from_xyz((0,rotation_y,0)),\n",
    "                'corners': translated_corners.T,\n",
    "                'real_center': real_center\n",
    "            })\n",
    "    return objects\n",
    "def create_oriented_bounding_box(box_params,offset=100,axis=0,calib=None,color=(1, 0, 0)):\n",
    "    offset_array = np.zeros(3)\n",
    "    offset_array[axis] = offset\n",
    "    center = np.array([box_params[0], box_params[1], box_params[2]/2])\n",
    "    extent = np.array([box_params[3], box_params[4], box_params[5]])\n",
    "    R = o3d.geometry.get_rotation_matrix_from_xyz((0,0,box_params[6]))\n",
    "\n",
    "    # Transform_lidar_to_cam = calib['Tr_velo_to_cam'].reshape(3, 4)\n",
    "    # extended_transform = np.eye(4)\n",
    "    # extended_transform[:3, :] = Transform_lidar_to_cam\n",
    "    # corners = np.array([center + np.dot(R, np.array([x, y, z])) for x in [-extent[0], extent[0]] for y in [-extent[1], extent[1]] for z in [-extent[2], extent[2]]])\n",
    "    # center_from_corners = np.mean(corners, axis=0)\n",
    "    # center  = center_from_corners\n",
    "    center += offset_array\n",
    "    R_empty = np.eye(3)\n",
    "    obb = o3d.geometry.OrientedBoundingBox(center=center, R=R, extent=extent)\n",
    "    obb.color = (1, 0, 0)  # Red color\n",
    "    return obb\n",
    "def create_oriented_bounding_box_nuscenes(detection, offset=100, axis=0, color=(1, 0, 0),calib=None):\n",
    "    offset_array = np.zeros(3)\n",
    "    offset_array[axis] = offset\n",
    "\n",
    "    # Extract parameters from the detection array\n",
    "    x, y, z, dx, dy, dz, r, _, _ = detection\n",
    "\n",
    "    # Define the center and extent of the box\n",
    "    center = np.array([x, y, z/2])\n",
    "    extent = np.array([dx, dy, dz])\n",
    "\n",
    "    # Create the rotation matrix from the heading angle\n",
    "    R = o3d.geometry.get_rotation_matrix_from_xyz((0, 0, 0 ))\n",
    "\n",
    "    # Apply the offset to the center\n",
    "    center += offset_array\n",
    "\n",
    "    # Create the Oriented Bounding Box\n",
    "    obb = o3d.geometry.OrientedBoundingBox(center=center, R=R, extent=extent)\n",
    "    obb.color = color  # Set the color\n",
    "    obb_for_center = o3d.geometry.OrientedBoundingBox(center=center, R=R, extent=[0.1,0.1,0.1])\n",
    "    obb_for_center.color = (1,1,1)\n",
    "    return obb , obb_for_center\n",
    "def rotate_points(points, R):\n",
    "    return np.dot(points, R.T)\n",
    "\n",
    "def match_detections_3d(ground_truths, predictions, iou_threshold=0.5):\n",
    "    matches = []\n",
    "    unmatched_ground_truths = []\n",
    "    unmatched_predictions = list(predictions)\n",
    "\n",
    "    for gt in ground_truths:\n",
    "        max_iou = -1\n",
    "        max_iou_idx = -1\n",
    "        for idx, pred in enumerate(unmatched_predictions):\n",
    "            current_iou = calculate_iou_3d(gt, pred)\n",
    "            if current_iou > max_iou:\n",
    "                max_iou = current_iou\n",
    "                max_iou_idx = idx\n",
    "        # print(\"For gt\",gt,\"max iou is\",max_iou)\n",
    "        if max_iou >= iou_threshold:\n",
    "            matches.append((gt, unmatched_predictions[max_iou_idx]))\n",
    "            del unmatched_predictions[max_iou_idx]\n",
    "        else:\n",
    "            unmatched_ground_truths.append(gt)\n",
    "\n",
    "    return matches, unmatched_ground_truths, unmatched_predictions\n",
    "def calculate_iou_3d(box1,box2):\n",
    "    # Create corner points for both boxes\n",
    "    if type(box1) == o3d.geometry.OrientedBoundingBox:\n",
    "        center1 = np.array(box1.center)\n",
    "        dimensions1 = np.array(box1.extent)\n",
    "        half_dims1 = dimensions1 / 2\n",
    "        corners1 = np.array([np.array([x, y, z]) for x in [-half_dims1[0], half_dims1[0]] for y in [-half_dims1[1], half_dims1[1]] for z in [-half_dims1[2], half_dims1[2]]])\n",
    "        corners1 = rotate_points(corners1, box1.R) + center1\n",
    "\n",
    "    else:\n",
    "        #get corners from lineset\n",
    "        # print(\"Getting corners from lineset\")\n",
    "        corners1 = np.array(box1.points)\n",
    "        dimensions_from_corners = np.max(corners1,axis=0) - np.min(corners1,axis=0)\n",
    "        dimensions1 = dimensions_from_corners\n",
    "        \n",
    "    if type(box2)== o3d.geometry.OrientedBoundingBox:\n",
    "        center2 = np.array(box2.center)\n",
    "        dimensions2 = np.array(box2.extent)\n",
    "        half_dims2 = dimensions2 / 2\n",
    "        corners2 = np.array([np.array([x, y, z]) for x in [-half_dims2[0], half_dims2[0]] for y in [-half_dims2[1], half_dims2[1]] for z in [-half_dims2[2], half_dims2[2]]])\n",
    "        # Rotate and translate corners\n",
    "        corners2 = rotate_points(corners2, box2.R) + center2\n",
    "    else:\n",
    "        #get corners from lineset\n",
    "        # print(\"Getting corners from lineset\")\n",
    "\n",
    "        corners2 = np.array(box2.points)\n",
    "        dimensions_from_corners = np.max(corners2,axis=0) - np.min(corners2,axis=0)\n",
    "        dimensions2 = dimensions_from_corners\n",
    "    # Calculate axis-aligned bounding boxes for intersection\n",
    "    min_bound1 = np.min(corners1, axis=0)\n",
    "    max_bound1 = np.max(corners1, axis=0)\n",
    "    min_bound2 = np.min(corners2, axis=0)\n",
    "    max_bound2 = np.max(corners2, axis=0)\n",
    "    \n",
    "    # Calculate intersection\n",
    "    min_intersect = np.maximum(min_bound1, min_bound2)\n",
    "    max_intersect = np.minimum(max_bound1, max_bound2)\n",
    "    intersection_dims = np.maximum(0, max_intersect - min_intersect)\n",
    "    intersection_volume = np.prod(intersection_dims)\n",
    "    \n",
    "    # Calculate volumes of the individual boxes\n",
    "    vol1 = np.prod(dimensions1)\n",
    "    vol2 = np.prod(dimensions2)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_volume / (vol1 + vol2 - intersection_volume)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def is_point_inside_obb(obb, point):\n",
    "    \"\"\"\n",
    "    Check if a point is inside an oriented bounding box (OBB).\n",
    "    \n",
    "    Parameters:\n",
    "    - obb: Open3D OrientedBoundingBox object.\n",
    "    - point: NumPy array of shape (3,) representing the point.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the point is inside the OBB, False otherwise.\n",
    "    \"\"\"\n",
    "    # Transform the point to the OBB's local coordinate system\n",
    "    point_local = np.linalg.inv(obb.R).dot((point[:3] - obb.center))\n",
    "    \n",
    "    # Check if the transformed point is inside the axis-aligned box\n",
    "    return np.all(np.abs(point_local) <= (obb.extent / 2))\n",
    "\n",
    "def remove_points_inside_obbs(point_cloud, obbs):\n",
    "    \"\"\"\n",
    "    Remove points inside oriented bounding boxes from a point cloud.\n",
    "    \n",
    "    Parameters:\n",
    "    - point_cloud: NumPy array of shape (N, 3), where N is the number of points.\n",
    "    - obbs: List of Open3D OrientedBoundingBox objects.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_point_cloud: NumPy array containing points outside the bounding boxes.\n",
    "    \"\"\"\n",
    "    mask = np.ones(point_cloud.shape[0], dtype=bool)\n",
    "    \n",
    "    for obb in obbs:\n",
    "        for i, point in enumerate(point_cloud):\n",
    "            if is_point_inside_obb(obb, point):\n",
    "                mask[i] = False\n",
    "    \n",
    "    filtered_point_cloud = point_cloud[mask]\n",
    "    \n",
    "    return filtered_point_cloud\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import open3d as o3d\n",
    "import mmdet3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from plyfile import PlyData\n",
    "from mmcv.transforms.base import BaseTransform\n",
    "from mmengine.registry import TRANSFORMS, VISUALIZERS\n",
    "from mmengine.structures import InstanceData\n",
    "from mmdet3d.utils import register_all_modules\n",
    "from mmdet3d.apis import inference_detector, init_model\n",
    "from mmdet3d.evaluation.metrics.nuscenes_metric import NuScenesMetric\n",
    "from mmdet3d.datasets import NuScenesDataset\n",
    "from mmdet3d.structures import Det3DDataSample, LiDARInstance3DBoxes\n",
    "from mmdet3d.visualization import Det3DLocalVisualizer\n",
    "from mmdet3d.structures import LiDARInstance3DBoxes\n",
    "def load_velodyne_points(filename):\n",
    "    points = np.fromfile(filename, dtype=np.float32).reshape(-1, 4)\n",
    "    return points\n",
    "def read_calib_file(calib_file):\n",
    "    with open(calib_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        calibration = {}\n",
    "\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            try:\n",
    "                key, value = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            calibration[key] = np.array([float(x) for x in value.strip().split()])\n",
    "        return calibration\n",
    "def read_kitti_label_file(bin_file_path, filter_classes=['Car', 'Pedestrian', 'Cyclist']):\n",
    "    \"\"\"\n",
    "    Reads a KITTI label .txt file and returns a list of dictionaries containing\n",
    "    object type and bounding box parameters, filtered by specified classes.\n",
    "\n",
    "    Parameters:\n",
    "        txt_file_path (str): Path to the KITTI label .txt file.\n",
    "        filter_classes (List[str]): List of classes to include.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: A list of dictionaries containing 'type', 'x', 'y', 'z', 'dx', 'dy', 'dz', and 'yaw'.\n",
    "    \"\"\"\n",
    "    txt_file_path = bin_file_path.replace('.bin', '.txt').replace(\"velodyne\",\"label_2\")\n",
    "    calib_file_path = bin_file_path.replace('.bin', '.txt').replace(\"velodyne\",\"calib\")\n",
    "    calib = read_calib_file(calib_file_path)\n",
    "    objects = []\n",
    "    from math import cos,sin\n",
    "\n",
    "    with open(txt_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.strip().split(' ')\n",
    "            obj_type = tokens[0]\n",
    "            if obj_type not in filter_classes:\n",
    "                continue\n",
    "            # print(line)\n",
    "            dimensions_height, dimensions_width, dimensions_length = map(float, tokens[8:11])\n",
    "            location_x, location_y, location_z = map(float, tokens[11:14])\n",
    "            center_tr = np.array([location_x, location_y, location_z])\n",
    "            rotation_y = float(tokens[14])\n",
    "            l_div_2 = dimensions_length / 2\n",
    "            x_corners = [l_div_2, l_div_2, -l_div_2, -l_div_2, l_div_2, l_div_2, -l_div_2, -l_div_2]\n",
    "            w_div_2 = dimensions_width / 2\n",
    "            y_corners = [0, 0, 0, 0, -dimensions_height, -dimensions_height, -dimensions_height, -dimensions_height]\n",
    "            z_corners = [w_div_2, -w_div_2, -w_div_2, w_div_2, w_div_2, -w_div_2, -w_div_2, w_div_2]\n",
    "            corner_matrix = np.array([x_corners, y_corners, z_corners])\n",
    "            R = np.array([[cos(rotation_y),0,sin(rotation_y)],[0,1,0],[-sin(rotation_y),0,cos(rotation_y)]])\n",
    "            rotated_corners = np.matmul(R,corner_matrix)\n",
    "            translated_corners = rotated_corners + center_tr.reshape(3,1)\n",
    "            \n",
    "            Tr_velo_to_cam = calib['Tr_velo_to_cam'].reshape(3, 4)\n",
    "            Tr_velo_to_cam_extended = np.eye(4)  # Create a 4x4 identity matrix\n",
    "            Tr_velo_to_cam_extended[:3, :] = Tr_velo_to_cam  # Replace the top-left 3x4 block\n",
    "            \n",
    "            # rotation_component = np.eye(4)\n",
    "            # rotation_component[:3,:3] = Tr_velo_to_cam_extended[:3,:3]\n",
    "            \n",
    "            # translation_component = np.eye(4)\n",
    "            # translation_component[:3,3] = Tr_velo_to_cam_extended[:3,3]\n",
    "            \n",
    "            # inverse_rotation = np.linalg.inv(rotation_component)\n",
    "            # inverse_translation =  -translation_component\n",
    "            \n",
    "            # new_transform = np.eye(4)\n",
    "            # new_transform[:3,:3] = inverse_rotation[:3,:3]\n",
    "            # new_transform[:3,3] = inverse_translation[:3,3]\n",
    "\n",
    "            # print(new_transform.shape,translated_corners.shape)\n",
    "            T_inv = np.linalg.inv(Tr_velo_to_cam_extended)\n",
    "            Homogeneous_corners = np.ones((4,8))\n",
    "            Homogeneous_corners[:3,:] = translated_corners\n",
    "            translated_corners = np.matmul(T_inv,Homogeneous_corners)[:3,:]\n",
    "            real_center = np.mean(translated_corners,axis=1)\n",
    "            # print(translated_corners.shape)\n",
    "            # real_center = np.mean(translated_corners,axis=1)\n",
    "            # print(real_center)\n",
    "            objects.append({\n",
    "                'type': obj_type,\n",
    "                'x': real_center[0],\n",
    "                'y': real_center[1],\n",
    "                'z': real_center[2],\n",
    "                'dx': dimensions_length,\n",
    "                'dy': dimensions_height,\n",
    "                'dz': dimensions_width,\n",
    "                'yaw': o3d.geometry.get_rotation_matrix_from_xyz((0,rotation_y,0)),\n",
    "                'corners': translated_corners.T,\n",
    "                'real_center': real_center\n",
    "            })\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "kitti_velodyne_path= r\"D:\\introspectionBase\\datasets\\Kitti\\raw\\training\\velodyne\"\n",
    "dataset_path = r\"D:\\Introspect3D\\custom_dataset\\pointpillars_kitti_class3\"\n",
    "flag = 0\n",
    "\n",
    "def myhook(module, input, output):\n",
    "    global im_name,dataset_path,flag\n",
    "    # print(output[0].shape,output[1].shape,output[2].shape)\n",
    "    numpy_output = output[2].squeeze().cpu().detach().numpy()\n",
    "    # print(numpy_output.shape)\n",
    "    # print(f\"Saving to {os.path.join(dataset_path,im_name.replace('.png','.npy'))}\")\n",
    "    if(flag):\n",
    "        np.save(os.path.join(dataset_path,'features',im_name.replace(\".png\",\".npy\")),numpy_output)\n",
    "    else:\n",
    "        np.save(os.path.join(dataset_path,'features_removed',im_name.replace(\".png\",\".npy\")),numpy_output)\n",
    "def read_calib_file(calib_file):\n",
    "    with open(calib_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        calibration = {}\n",
    "\n",
    "        for line in lines:\n",
    "            # print(line)\n",
    "            try:\n",
    "                key, value = line.split(':')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            calibration[key] = np.array([float(x) for x in value.strip().split()])\n",
    "        return calibration\n",
    "if __name__ == \"__main__\":\n",
    "    # build the model from a config file and a checkpoint file\n",
    "    config_file = r'D:\\mmdetection3d\\configs\\pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-3class.py'\n",
    "    # download the checkpoint from model zoo and put it in `checkpoints/`\n",
    "    checkpoint = r'D:\\mmdetection3d/ckpts/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth'\n",
    "    model = init_model(config_file, checkpoint, device='cuda:0')\n",
    "\n",
    "    hook = model.backbone.register_forward_hook(myhook)\n",
    "    score_threshold = 0.5\n",
    "    with tqdm(total=7480) as pbar:\n",
    "        for i in range(7480):\n",
    "            test_num  = i\n",
    "            filename = os.path.join(kitti_velodyne_path, f'{test_num:06}.bin')\n",
    "            calib_data = read_calib_file(filename.replace('.bin', '.txt').replace(\"velodyne\",\"calib\"))\n",
    "            points = load_velodyne_points(filename)\n",
    "\n",
    "            im_name = f'{test_num:06}.png'           \n",
    "            # Transformation matrix is in (3x4) shape, so we extend it to (4x4) by adding a row of [0,0,0,1] for homogeneous coordinates\n",
    "            Tr_velo_to_cam = calib_data['Tr_velo_to_cam'].reshape(3, 4)\n",
    "            Tr_velo_to_cam_extended = np.eye(4)  # Create a 4x4 identity matrix\n",
    "            Tr_velo_to_cam_extended[:3, :] = Tr_velo_to_cam  # Replace the top-left 3x4 block\n",
    "            \n",
    "            max_distance = np.max(np.linalg.norm(points[:, :3], axis=1))\n",
    "            a, b = 25, 15  # Semi-major and semi-minor axes\n",
    "            filtered_points = filter_points_inside_ellipse(points, a, b,offset=-10) #filter_points_inside_pyramid(points, min_x, max_x, min_y,max_y ) #\n",
    "            filtered_pcd = create_point_cloud(filtered_points,distance=max_distance)\n",
    "            outside_points = filter_points_outside_ellipse(filtered_points, a, b,offset=-10)\n",
    "            outside_pcd = create_point_cloud(outside_points)\n",
    "            flag = 1\n",
    "            res_f,data_f = inference_detector(model, filtered_points)\n",
    "            pred_boxes_box_f = res_f.pred_instances_3d.bboxes_3d.tensor.cpu().numpy()\n",
    "            pred_boxes_score_f = res_f.pred_instances_3d.scores_3d.cpu().numpy()\n",
    "            filtered_indices = np.where(pred_boxes_score_f >= score_threshold)[0]\n",
    "            filtered_boxes = pred_boxes_box_f[filtered_indices]\n",
    "            obb_list_f = [create_oriented_bounding_box(box,offset=0,calib=calib_data) for box in filtered_boxes]\n",
    "            removed_object_points = remove_points_inside_obbs(filtered_points, obb_list_f)\n",
    "            flag = 0\n",
    "            # removed_pcd = create_point_cloud(removed_object_points,distance=max_distance)\n",
    "            one_more_chance_res, one_more_chance_data = inference_detector(model, removed_object_points)\n",
    "            # one_more_chance_pred_boxes_box = one_more_chance_res.pred_instances_3d.bboxes_3d.tensor.cpu().numpy()\n",
    "            # one_more_chance_pred_boxes_score = one_more_chance_res.pred_instances_3d.scores_3d.cpu().numpy()\n",
    "            # filtered_indices = np.where(one_more_chance_pred_boxes_score >= score_threshold)[0]\n",
    "            # one_more_chance_filtered_boxes = one_more_chance_pred_boxes_box[filtered_indices]\n",
    "            # one_more_chance_obb_list_f = [create_oriented_bounding_box(box,offset=0,calib=calib_data,color=(1,0.647,0)) for box in one_more_chance_filtered_boxes]\n",
    "\n",
    "            # test a single sample\n",
    "            # print(points.shape)\n",
    "            # points = np.expand_dims(points,axis=0)\n",
    "            # res = inference_detector(model,points)  \n",
    "            pbar.update(1)\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    config_file = r'D:\\mmdetection3d\\configs\\pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-3class.py'\n",
    "    # download the checkpoint from model zoo and put it in `checkpoints/`\n",
    "    checkpoint = r'D:\\mmdetection3d/ckpts/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth'\n",
    "    model = init_model(config_file, checkpoint, device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array(np.random.rand(8,3))\n",
    "offset = np.array([0,10,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    print(x)\n",
    "\n",
    "eval('f'(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nuscenes.nuscenes import NuScenes\n",
    "nusc = NuScenes(version='v1.0-mini', dataroot='path/to/nuscenes/data', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Initial setup\n",
    "from typing import Optional\n",
    "import warnings\n",
    "# Disable annoying warnings from PyArrow using under the hood.\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import dask.dataframe as dd\n",
    "from waymo_open_dataset import v2\n",
    "from glob import glob\n",
    "\n",
    "# Path to the directory with all components\n",
    "dataset_dir = '/mnt/ssd2/waymo/training'\n",
    "\n",
    "context_name = '10023947602400723454_1120_000_1140_000'\n",
    "\n",
    "def read(tag: str) -> dd.DataFrame:\n",
    "  \"\"\"Creates a Dask DataFrame for the component specified by its tag.\"\"\"\n",
    "  print('Reading',f'{dataset_dir}/{tag}/{context_name}.parquet')\n",
    "  paths = tf.io.gfile.glob(f'{dataset_dir}/{tag}/*.parquet')#{context_name}\n",
    "  print(paths)\n",
    "  return dd.read_parquet(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_df = read('lidar')\n",
    "lidar_pose_df = read('lidar_pose')\n",
    "lidar_calibration_df = read('lidar_calibration')\n",
    "lidar_segmentation_df = read('lidar_segmentation')\n",
    "stats_df = read('stats')\n",
    "vehicle_pose_df = read('vehicle_pose')\n",
    "\n",
    "\n",
    "_, lidar_row = next(iter(lidar_df.iterrows()))\n",
    "_, lidar_pose_row = next(iter(lidar_pose_df.iterrows()))\n",
    "_, lidar_calibration_row = next(iter(lidar_calibration_df.iterrows()))\n",
    "_, lidar_segmentation_row = next(iter(lidar_segmentation_df.iterrows()))\n",
    "_, vehicle_pose_row = next(iter(vehicle_pose_df.iterrows()))\n",
    "\n",
    "lidar = v2.LiDARComponent.from_dict(lidar_row)\n",
    "lidar_pose = v2.LiDARPoseComponent.from_dict(lidar_pose_row)\n",
    "lidar_calibration = v2.LiDARCalibrationComponent.from_dict(lidar_calibration_row)\n",
    "lidar_segmentation = v2.LiDARSegmentationLabelComponent.from_dict(lidar_segmentation_row)\n",
    "vehicle_pose = v2.VehiclePoseComponent.from_dict(vehicle_pose_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waymo_open_dataset.v2.perception.utils import lidar_utils\n",
    "points = lidar_utils.convert_range_image_to_point_cloud(lidar.range_image_return1,\n",
    "                                                        lidar_calibration,\n",
    "                                                        lidar_pose.range_image_return1,\n",
    "                                                        vehicle_pose,\n",
    "                                                        False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = v2.merge(lidar_df, lidar_box_df, left_group=True, right_group=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = v2.merge(lidar_df, lidar_box_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lidar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, row = next(iter(df2.iterrows()))\n",
    "lidar = v2.LiDARComponent.from_dict(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
